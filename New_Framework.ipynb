{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "New_Framework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazabdul7/AtTheEdge/blob/main/New_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TkbPWTn8bMo"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "from tensorflow.keras import layers\n",
        "import zipfile as zf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF59vbrkHuOp"
      },
      "source": [
        "files = zf.ZipFile(\"dataYoupengSplit.zip\",'r')\n",
        "files.extractall()\n",
        "files.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gndf-p0pSoll",
        "outputId": "37e83f5a-890c-4ef9-c9fe-cc9224a0de6d"
      },
      "source": [
        "#pip install -q tensorflow-model-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10kB 29.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 21.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 15.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 15.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 13.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG8irch_7jak"
      },
      "source": [
        "print(tf.__version__) # TF Version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPxoL8wy8bMt"
      },
      "source": [
        "Generates a data object with the dataset. Splits 80/20 test/val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iUVIDtO8bMu"
      },
      "source": [
        "batch_size = 16\n",
        "img_height = 288\n",
        "img_width = 384\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  r'/content/main',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=777,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  r'/content/main',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=777,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "#Print number of samples\n",
        "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
        "print(\n",
        "    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(val_ds)\n",
        ")\n",
        "\n",
        "print(\"The labels for the ds: %s\" % train_ds.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu6a1Z958bM2"
      },
      "source": [
        "#Visualise the inputs\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ06RhRd8bM4"
      },
      "source": [
        "#Set cache and prefetch for drive disk performance\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymyKCV9z8bM6"
      },
      "source": [
        "#Augment training data to reduce overfitting by creating a pre-proccessing layer that only activates in training\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"), #random hor flip\n",
        "        layers.experimental.preprocessing.RandomFlip(\"vertical\"), # random ver flip\n",
        "        layers.experimental.preprocessing.RandomRotation(0.5), #random rotation up to 180deg\n",
        "        layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1, fill_mode='reflect'), #translation\n",
        "        layers.experimental.preprocessing.RandomZoom((0, -1), (0, -1)), #up to 100% zoom\n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEZfc0KT8bM8"
      },
      "source": [
        "#Visualise transformations on a sample image \n",
        "for images, labels in train_ds.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = images[4]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(\n",
        "            tf.expand_dims(first_image, 0), training=True\n",
        "        )\n",
        "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToQTKhDVtLaK"
      },
      "source": [
        "Begin building out models!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmRhJBdR8bM-"
      },
      "source": [
        "#Build our model\n",
        "\n",
        "base_model = keras.applications.EfficientNetB0(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGDGj9Hs8tNZ"
      },
      "source": [
        "#View the layers in the base model\n",
        "#May want to avoid models with advanced layering e.g squeeze, unsqueeze... as they may cause issues when utilising TensorRT later. There are workarounds though.\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqc8L_un8bNB"
      },
      "source": [
        "# Unfreeze base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=( img_height, img_width, 3))\n",
        "x = data_augmentation(inputs)  # Apply random data augmentation"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPZPUBS88bNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5569357d-108e-46e9-edb5-25996a50ae0b"
      },
      "source": [
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "#x = keras.layers.BatchNormalization()(x)\n",
        "#x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "outputs = keras.layers.Dense(5, activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs,)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 288, 384, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 288, 384, 3)       0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, 9, 12, 1280)       4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 6405      \n",
            "=================================================================\n",
            "Total params: 4,055,976\n",
            "Trainable params: 4,013,953\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xyiGxD__GlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b495d743-0f7d-497a-c171-d933d546e15a"
      },
      "source": [
        "#Train model with low LR as suggested in the report\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(4.3e-5),  # Low learning rate identified by lowest loss within the first 5 epochs\n",
        "    loss=\"sparse_categorical_crossentropy\" ,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "epochs = 33\n",
        "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 288, 384, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 288, 384, 3)       0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, 9, 12, 1280)       4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 6405      \n",
            "=================================================================\n",
            "Total params: 4,055,976\n",
            "Trainable params: 4,013,953\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "  2/108 [..............................] - ETA: 35s - loss: 0.0767 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1394s vs `on_train_batch_end` time: 0.2699s). Check your callbacks.\n",
            "108/108 [==============================] - 45s 421ms/step - loss: 0.2060 - accuracy: 0.9245 - val_loss: 0.2053 - val_accuracy: 0.9488\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 44s 405ms/step - loss: 0.2023 - accuracy: 0.9228 - val_loss: 0.1906 - val_accuracy: 0.9465\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 44s 404ms/step - loss: 0.2206 - accuracy: 0.9239 - val_loss: 0.1732 - val_accuracy: 0.9535\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 44s 404ms/step - loss: 0.1863 - accuracy: 0.9321 - val_loss: 0.2335 - val_accuracy: 0.9442\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 44s 405ms/step - loss: 0.1874 - accuracy: 0.9245 - val_loss: 0.2103 - val_accuracy: 0.9419\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 44s 408ms/step - loss: 0.2139 - accuracy: 0.9175 - val_loss: 0.1949 - val_accuracy: 0.9512\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 43s 402ms/step - loss: 0.1945 - accuracy: 0.9315 - val_loss: 0.2580 - val_accuracy: 0.9395\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 43s 403ms/step - loss: 0.1769 - accuracy: 0.9297 - val_loss: 0.2180 - val_accuracy: 0.9488\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 43s 399ms/step - loss: 0.1865 - accuracy: 0.9280 - val_loss: 0.2310 - val_accuracy: 0.9465\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 44s 404ms/step - loss: 0.1826 - accuracy: 0.9350 - val_loss: 0.1963 - val_accuracy: 0.9465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fca7005b2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1zSuVY_8bNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad46cd05-69ca-42b2-c02e-3660dec07dc6"
      },
      "source": [
        "#Retrain at a lower learning rate for stability\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=4e-6),\n",
        "    loss=\"sparse_categorical_crossentropy\" ,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "epochs = 5\n",
        "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "  2/108 [..............................] - ETA: 33s - loss: 0.0627 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1394s vs `on_train_batch_end` time: 0.2396s). Check your callbacks.\n",
            "108/108 [==============================] - 45s 416ms/step - loss: 0.1400 - accuracy: 0.9472 - val_loss: 0.1902 - val_accuracy: 0.9465\n",
            "Epoch 2/5\n",
            "108/108 [==============================] - 43s 398ms/step - loss: 0.1656 - accuracy: 0.9373 - val_loss: 0.1861 - val_accuracy: 0.9535\n",
            "Epoch 3/5\n",
            "108/108 [==============================] - 43s 401ms/step - loss: 0.1534 - accuracy: 0.9448 - val_loss: 0.1853 - val_accuracy: 0.9512\n",
            "Epoch 4/5\n",
            "108/108 [==============================] - 43s 399ms/step - loss: 0.1457 - accuracy: 0.9454 - val_loss: 0.1887 - val_accuracy: 0.9442\n",
            "Epoch 5/5\n",
            "108/108 [==============================] - 43s 401ms/step - loss: 0.1296 - accuracy: 0.9512 - val_loss: 0.1792 - val_accuracy: 0.9558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc850b925c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk7zUmuwSdFh"
      },
      "source": [
        "IMPORT EXPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WCLTty6r-LW"
      },
      "source": [
        "#Save whole model\n",
        "model.save('EfficientNetB0Small2.h5', include_optimizer=False) \n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4fIkY0t7UxE"
      },
      "source": [
        "#load model\n",
        "model = tf.keras.models.load_model('EfficientNetB0.75', compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA-fYtbsSa0F"
      },
      "source": [
        "TEST BENCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vcat_cC9B6a"
      },
      "source": [
        "files = zf.ZipFile(\"B0.zip\",'r')\n",
        "files.extractall()\n",
        "files.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36qbwQnez5fC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9fc6514-1ff4-4911-f4f6-58e744865b00"
      },
      "source": [
        "#Import test set as images\n",
        "img = keras.preprocessing.image.DirectoryIterator(\n",
        "    r'/content/test', tf.keras.preprocessing.image.ImageDataGenerator(), target_size=(img_height, img_width), batch_size=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 238 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AduoAtf0UePg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe731a4-ba0f-46ca-a6c1-c5d89516158c"
      },
      "source": [
        "#Calculate accuracy against test set\n",
        "labels = [\"cardboard\", \"glass\", \"metal\", \"paper\", \"plastic\"]\n",
        "acc = 0\n",
        "for i in range(len(img)):\n",
        "  predictions = model.predict(img[i])\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "  for j in img[i][1]:\n",
        "    if np.argmax(score) == j.tolist().index(1):\n",
        "      acc += 1\n",
        "    #Prints confidence of each inference\n",
        "    #print(\"%s:%s %.2f\" % (labels[np.argmax(score)], labels[j.tolist().index(1)], predictions[0][np.argmax(score)]*100))\n",
        "print(\"The accuracy against the test set was found to be: \" + str((acc/len(img))*100) + \"%\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy against the test set was found to be: 95.37815126050421%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C59Yzslk4Mu",
        "outputId": "cff1e9ac-aecb-469f-f5c7-e82d55ed9bc5"
      },
      "source": [
        "#TFLite Converter (No longer used for project)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('B0TFlite2.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmputmep6/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmputmep6/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjlrs1mIUgtM"
      },
      "source": [
        "TRT ENGINE OPTIMISATIONS\n",
        "\n",
        "**These MUST be carried out on the device that the model will be run on as optimisations are made specifically for the available GPUS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NWTxlQ7EEnZ"
      },
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lZp4sG3Czog"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "#set engine parameters\n",
        "conversion_params = tf.experimental.tensorrt.ConversionParams(max_workspace_size_bytes=1<<25, precision_mode='FP16', max_batch_size = 1)\n",
        "\n",
        "#int8 gen\n",
        "def input_fn():\n",
        "    for i in range(10):\n",
        "        yield tf.random.normal((1, 512, 384, 3))\n",
        "#convert the model to a graph\n",
        "converter = trt.TrtGraphConverterV2(\n",
        "    input_saved_model_dir='EfficientNetB0',\n",
        "    conversion_params=conversion_params)\n",
        "\n",
        "converter.convert() # convert subgraphs\n",
        "\n",
        "#providing sample inputs here allows engines to be created ahead of time which saves costs at inference (removes overheads)\n",
        "def my_input_fn():\n",
        "# Input for a single inference call, for a network that has two input tensors:\n",
        "  inp1 = img[0][0]\n",
        "  inp2 = img[1][0]\n",
        "  yield (inp1)\n",
        "\n",
        "#build and save model\n",
        "converter.build(input_fn=my_input_fn)\n",
        "converter.save('TRTModel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCKS_hF0DgBx"
      },
      "source": [
        "#load optimised graph\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "from tensorflow.python.saved_model import signature_constants, tag_constants\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "import time\n",
        "saved_model_loaded = tf.saved_model.load(\n",
        "    'content/new3', tags=[tag_constants.SERVING])\n",
        "\n",
        "graph_func = saved_model_loaded.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdEu45e8Za47",
        "outputId": "900e732f-dda5-4e78-ecfc-092529b8556e"
      },
      "source": [
        "#test accuracy\n",
        "acc = 0\n",
        "for i in range(len(img)):\n",
        "  x = tf.constant(img[i][0])\n",
        "  predictions = graph_func(x)\n",
        "  score = tf.nn.softmax(predictions.get('dense').numpy()[0])\n",
        "  for j in img[i][1]:\n",
        "    if np.argmax(score) == j.tolist().index(1):\n",
        "      acc += 1\n",
        "print(\"The accuracy against the test set was found to be: \" + str((acc/len(img))*100) + \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy against the test set was found to be: 95.37815126050421%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ly8s53DaPqU"
      },
      "source": [
        "#tf.constant(np.expand_dims(img[1][0], axis = 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3jGzdpPJYer"
      },
      "source": [
        "#img = tf.keras.preprocessing.image.load_img('/content/test/cardboard/cardboard101.jpg', target_size=(512, 384))\n",
        "#x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "#x = np.array([x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s3IDGJxZYWw"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttX2uIuBNmqN",
        "outputId": "48bd6b12-75fc-4b54-abd7-b303d6162d28"
      },
      "source": [
        "#Zip savedmodels and export for download\n",
        "!zip -r /content/B075.zip /content/EfficientNetB0.75"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: content/EfficientNetB0.75/ (stored 0%)\n",
            "updating: content/EfficientNetB0.75/variables/ (stored 0%)\n",
            "updating: content/EfficientNetB0.75/variables/variables.index (deflated 78%)\n",
            "updating: content/EfficientNetB0.75/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "updating: content/EfficientNetB0.75/assets/ (stored 0%)\n",
            "updating: content/EfficientNetB0.75/saved_model.pb (deflated 92%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}